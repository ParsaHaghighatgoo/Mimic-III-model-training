{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# This is a sample Jupyter Notebook\n",
    "\n",
    "Below is an example of a code cell. \n",
    "Put your cursor into the cell and press Shift+Enter to execute it and select the next one, or click 'Run Cell' button.\n",
    "\n",
    "Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "\n",
    "To learn more about Jupyter Notebooks in PyCharm, see [help](https://www.jetbrains.com/help/pycharm/ipython-notebook-support.html).\n",
    "For an overview of PyCharm, go to Help -> Learn IDE features or refer to [our documentation](https://www.jetbrains.com/help/pycharm/getting-started.html)."
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T08:55:31.414049Z",
     "start_time": "2024-12-05T08:55:31.408666Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"Hello World!\")\n",
   "id": "fbc121e30a2defb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T09:03:28.397005Z",
     "start_time": "2024-12-05T08:56:27.448619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from holoviews.plotting.bokeh.styles import alpha\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# importing csv\n",
    "df = pd.read_csv('CHARTEVENTS.csv')\n",
    "df.info()"
   ],
   "id": "bac2de5aaf956775",
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.46 GiB for an array with shape (330712483,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 20\u001B[0m\n\u001B[0;32m     18\u001B[0m warnings\u001B[38;5;241m.\u001B[39mfilterwarnings(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# importing csv\u001B[39;00m\n\u001B[1;32m---> 20\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCHARTEVENTS.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     21\u001B[0m df\u001B[38;5;241m.\u001B[39minfo()\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[0;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m   1014\u001B[0m     dialect,\n\u001B[0;32m   1015\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[0;32m   1023\u001B[0m )\n\u001B[0;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n\u001B[0;32m    625\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m parser:\n\u001B[1;32m--> 626\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\u001B[38;5;241m.\u001B[39mread(nrows)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001B[0m, in \u001B[0;36mTextFileReader.read\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m   1916\u001B[0m nrows \u001B[38;5;241m=\u001B[39m validate_integer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnrows\u001B[39m\u001B[38;5;124m\"\u001B[39m, nrows)\n\u001B[0;32m   1917\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1918\u001B[0m     \u001B[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001B[39;00m\n\u001B[0;32m   1919\u001B[0m     (\n\u001B[0;32m   1920\u001B[0m         index,\n\u001B[0;32m   1921\u001B[0m         columns,\n\u001B[0;32m   1922\u001B[0m         col_dict,\n\u001B[1;32m-> 1923\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mread(  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[0;32m   1924\u001B[0m         nrows\n\u001B[0;32m   1925\u001B[0m     )\n\u001B[0;32m   1926\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m   1927\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:236\u001B[0m, in \u001B[0;36mCParserWrapper.read\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m    234\u001B[0m     chunks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reader\u001B[38;5;241m.\u001B[39mread_low_memory(nrows)\n\u001B[0;32m    235\u001B[0m     \u001B[38;5;66;03m# destructive to chunks\u001B[39;00m\n\u001B[1;32m--> 236\u001B[0m     data \u001B[38;5;241m=\u001B[39m _concatenate_chunks(chunks)\n\u001B[0;32m    238\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    239\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reader\u001B[38;5;241m.\u001B[39mread(nrows)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:376\u001B[0m, in \u001B[0;36m_concatenate_chunks\u001B[1;34m(chunks)\u001B[0m\n\u001B[0;32m    374\u001B[0m     result[name] \u001B[38;5;241m=\u001B[39m union_categoricals(arrs, sort_categories\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    375\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 376\u001B[0m     result[name] \u001B[38;5;241m=\u001B[39m concat_compat(arrs)\n\u001B[0;32m    377\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(non_cat_dtypes) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m result[name]\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m np\u001B[38;5;241m.\u001B[39mdtype(\u001B[38;5;28mobject\u001B[39m):\n\u001B[0;32m    378\u001B[0m         warning_columns\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mstr\u001B[39m(name))\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\concat.py:78\u001B[0m, in \u001B[0;36mconcat_compat\u001B[1;34m(to_concat, axis, ea_compat_axis)\u001B[0m\n\u001B[0;32m     76\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj, np\u001B[38;5;241m.\u001B[39mndarray):\n\u001B[0;32m     77\u001B[0m     to_concat_arrs \u001B[38;5;241m=\u001B[39m cast(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSequence[np.ndarray]\u001B[39m\u001B[38;5;124m\"\u001B[39m, to_concat)\n\u001B[1;32m---> 78\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mconcatenate(to_concat_arrs, axis\u001B[38;5;241m=\u001B[39maxis)\n\u001B[0;32m     80\u001B[0m to_concat_eas \u001B[38;5;241m=\u001B[39m cast(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSequence[ExtensionArray]\u001B[39m\u001B[38;5;124m\"\u001B[39m, to_concat)\n\u001B[0;32m     81\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ea_compat_axis:\n\u001B[0;32m     82\u001B[0m     \u001B[38;5;66;03m# We have 1D objects, that don't support axis keyword\u001B[39;00m\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 2.46 GiB for an array with shape (330712483,) and data type int64"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T10:19:22.305236Z",
     "start_time": "2024-12-06T10:11:43.994261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the chunk size\n",
    "chunk_size = 10_000_000  # Number of rows to read at a time\n",
    "\n",
    "# Read the file in chunks\n",
    "chunk_iter = pd.read_csv('CHARTEVENTS.csv', chunksize=chunk_size)\n",
    "\n",
    "# Process each chunk\n",
    "for chunk in chunk_iter:\n",
    "    print(chunk.info())  # Display information about the chunk\n",
    "    # Perform operations on the chunk\n"
   ],
   "id": "86734f622892ab4a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 0 to 9999999\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ROW_ID        int64  \n",
      " 1   SUBJECT_ID    int64  \n",
      " 2   HADM_ID       int64  \n",
      " 3   ICUSTAY_ID    float64\n",
      " 4   ITEMID        int64  \n",
      " 5   CHARTTIME     object \n",
      " 6   STORETIME     object \n",
      " 7   CGID          float64\n",
      " 8   VALUE         float64\n",
      " 9   VALUENUM      float64\n",
      " 10  VALUEUOM      object \n",
      " 11  WARNING       int64  \n",
      " 12  ERROR         int64  \n",
      " 13  RESULTSTATUS  float64\n",
      " 14  STOPPED       float64\n",
      "dtypes: float64(6), int64(6), object(3)\n",
      "memory usage: 1.1+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 10000000 to 19999999\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ROW_ID        int64  \n",
      " 1   SUBJECT_ID    int64  \n",
      " 2   HADM_ID       int64  \n",
      " 3   ICUSTAY_ID    float64\n",
      " 4   ITEMID        int64  \n",
      " 5   CHARTTIME     object \n",
      " 6   STORETIME     object \n",
      " 7   CGID          float64\n",
      " 8   VALUE         float64\n",
      " 9   VALUENUM      float64\n",
      " 10  VALUEUOM      object \n",
      " 11  WARNING       int64  \n",
      " 12  ERROR         int64  \n",
      " 13  RESULTSTATUS  float64\n",
      " 14  STOPPED       float64\n",
      "dtypes: float64(6), int64(6), object(3)\n",
      "memory usage: 1.1+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 20000000 to 29999999\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ROW_ID        int64  \n",
      " 1   SUBJECT_ID    int64  \n",
      " 2   HADM_ID       int64  \n",
      " 3   ICUSTAY_ID    float64\n",
      " 4   ITEMID        int64  \n",
      " 5   CHARTTIME     object \n",
      " 6   STORETIME     object \n",
      " 7   CGID          float64\n",
      " 8   VALUE         float64\n",
      " 9   VALUENUM      float64\n",
      " 10  VALUEUOM      object \n",
      " 11  WARNING       int64  \n",
      " 12  ERROR         int64  \n",
      " 13  RESULTSTATUS  float64\n",
      " 14  STOPPED       float64\n",
      "dtypes: float64(6), int64(6), object(3)\n",
      "memory usage: 1.1+ GB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parsa\\AppData\\Local\\Temp\\ipykernel_20108\\3443397845.py:10: DtypeWarning: Columns (8,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in chunk_iter:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 30000000 to 39999999\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ROW_ID        int64  \n",
      " 1   SUBJECT_ID    int64  \n",
      " 2   HADM_ID       int64  \n",
      " 3   ICUSTAY_ID    float64\n",
      " 4   ITEMID        int64  \n",
      " 5   CHARTTIME     object \n",
      " 6   STORETIME     object \n",
      " 7   CGID          float64\n",
      " 8   VALUE         object \n",
      " 9   VALUENUM      float64\n",
      " 10  VALUEUOM      object \n",
      " 11  WARNING       float64\n",
      " 12  ERROR         float64\n",
      " 13  RESULTSTATUS  object \n",
      " 14  STOPPED       object \n",
      "dtypes: float64(5), int64(4), object(6)\n",
      "memory usage: 1.1+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 40000000 to 49999999\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ROW_ID        int64  \n",
      " 1   SUBJECT_ID    int64  \n",
      " 2   HADM_ID       int64  \n",
      " 3   ICUSTAY_ID    float64\n",
      " 4   ITEMID        int64  \n",
      " 5   CHARTTIME     object \n",
      " 6   STORETIME     object \n",
      " 7   CGID          int64  \n",
      " 8   VALUE         object \n",
      " 9   VALUENUM      float64\n",
      " 10  VALUEUOM      object \n",
      " 11  WARNING       float64\n",
      " 12  ERROR         float64\n",
      " 13  RESULTSTATUS  object \n",
      " 14  STOPPED       object \n",
      "dtypes: float64(4), int64(5), object(6)\n",
      "memory usage: 1.1+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 50000000 to 59999999\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ROW_ID        int64  \n",
      " 1   SUBJECT_ID    int64  \n",
      " 2   HADM_ID       int64  \n",
      " 3   ICUSTAY_ID    float64\n",
      " 4   ITEMID        int64  \n",
      " 5   CHARTTIME     object \n",
      " 6   STORETIME     object \n",
      " 7   CGID          int64  \n",
      " 8   VALUE         object \n",
      " 9   VALUENUM      float64\n",
      " 10  VALUEUOM      object \n",
      " 11  WARNING       float64\n",
      " 12  ERROR         float64\n",
      " 13  RESULTSTATUS  object \n",
      " 14  STOPPED       object \n",
      "dtypes: float64(4), int64(5), object(6)\n",
      "memory usage: 1.1+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 60000000 to 69999999\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ROW_ID        int64  \n",
      " 1   SUBJECT_ID    int64  \n",
      " 2   HADM_ID       int64  \n",
      " 3   ICUSTAY_ID    float64\n",
      " 4   ITEMID        int64  \n",
      " 5   CHARTTIME     object \n",
      " 6   STORETIME     object \n",
      " 7   CGID          int64  \n",
      " 8   VALUE         object \n",
      " 9   VALUENUM      float64\n",
      " 10  VALUEUOM      object \n",
      " 11  WARNING       float64\n",
      " 12  ERROR         float64\n",
      " 13  RESULTSTATUS  object \n",
      " 14  STOPPED       object \n",
      "dtypes: float64(4), int64(5), object(6)\n",
      "memory usage: 1.1+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 70000000 to 79999999\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ROW_ID        int64  \n",
      " 1   SUBJECT_ID    int64  \n",
      " 2   HADM_ID       int64  \n",
      " 3   ICUSTAY_ID    float64\n",
      " 4   ITEMID        int64  \n",
      " 5   CHARTTIME     object \n",
      " 6   STORETIME     object \n",
      " 7   CGID          int64  \n",
      " 8   VALUE         object \n",
      " 9   VALUENUM      float64\n",
      " 10  VALUEUOM      object \n",
      " 11  WARNING       float64\n",
      " 12  ERROR         float64\n",
      " 13  RESULTSTATUS  object \n",
      " 14  STOPPED       object \n",
      "dtypes: float64(4), int64(5), object(6)\n",
      "memory usage: 1.1+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 80000000 to 89999999\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ROW_ID        int64  \n",
      " 1   SUBJECT_ID    int64  \n",
      " 2   HADM_ID       int64  \n",
      " 3   ICUSTAY_ID    float64\n",
      " 4   ITEMID        int64  \n",
      " 5   CHARTTIME     object \n",
      " 6   STORETIME     object \n",
      " 7   CGID          int64  \n",
      " 8   VALUE         object \n",
      " 9   VALUENUM      float64\n",
      " 10  VALUEUOM      object \n",
      " 11  WARNING       float64\n",
      " 12  ERROR         float64\n",
      " 13  RESULTSTATUS  object \n",
      " 14  STOPPED       object \n",
      "dtypes: float64(4), int64(5), object(6)\n",
      "memory usage: 1.1+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 90000000 to 99999999\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ROW_ID        int64  \n",
      " 1   SUBJECT_ID    int64  \n",
      " 2   HADM_ID       int64  \n",
      " 3   ICUSTAY_ID    float64\n",
      " 4   ITEMID        int64  \n",
      " 5   CHARTTIME     object \n",
      " 6   STORETIME     object \n",
      " 7   CGID          int64  \n",
      " 8   VALUE         object \n",
      " 9   VALUENUM      float64\n",
      " 10  VALUEUOM      object \n",
      " 11  WARNING       float64\n",
      " 12  ERROR         float64\n",
      " 13  RESULTSTATUS  object \n",
      " 14  STOPPED       object \n",
      "dtypes: float64(4), int64(5), object(6)\n",
      "memory usage: 1.1+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 100000000 to 109999999\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ROW_ID        int64  \n",
      " 1   SUBJECT_ID    int64  \n",
      " 2   HADM_ID       int64  \n",
      " 3   ICUSTAY_ID    float64\n",
      " 4   ITEMID        int64  \n",
      " 5   CHARTTIME     object \n",
      " 6   STORETIME     object \n",
      " 7   CGID          int64  \n",
      " 8   VALUE         object \n",
      " 9   VALUENUM      float64\n",
      " 10  VALUEUOM      object \n",
      " 11  WARNING       float64\n",
      " 12  ERROR         float64\n",
      " 13  RESULTSTATUS  object \n",
      " 14  STOPPED       object \n",
      "dtypes: float64(4), int64(5), object(6)\n",
      "memory usage: 1.1+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 110000000 to 119999999\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ROW_ID        int64  \n",
      " 1   SUBJECT_ID    int64  \n",
      " 2   HADM_ID       int64  \n",
      " 3   ICUSTAY_ID    float64\n",
      " 4   ITEMID        int64  \n",
      " 5   CHARTTIME     object \n",
      " 6   STORETIME     object \n",
      " 7   CGID          int64  \n",
      " 8   VALUE         object \n",
      " 9   VALUENUM      float64\n",
      " 10  VALUEUOM      object \n",
      " 11  WARNING       float64\n",
      " 12  ERROR         float64\n",
      " 13  RESULTSTATUS  object \n",
      " 14  STOPPED       object \n",
      "dtypes: float64(4), int64(5), object(6)\n",
      "memory usage: 1.1+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 120000000 to 129999999\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ROW_ID        int64  \n",
      " 1   SUBJECT_ID    int64  \n",
      " 2   HADM_ID       int64  \n",
      " 3   ICUSTAY_ID    float64\n",
      " 4   ITEMID        int64  \n",
      " 5   CHARTTIME     object \n",
      " 6   STORETIME     object \n",
      " 7   CGID          int64  \n",
      " 8   VALUE         object \n",
      " 9   VALUENUM      float64\n",
      " 10  VALUEUOM      object \n",
      " 11  WARNING       float64\n",
      " 12  ERROR         float64\n",
      " 13  RESULTSTATUS  object \n",
      " 14  STOPPED       object \n",
      "dtypes: float64(4), int64(5), object(6)\n",
      "memory usage: 1.1+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 130000000 to 139999999\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ROW_ID        int64  \n",
      " 1   SUBJECT_ID    int64  \n",
      " 2   HADM_ID       int64  \n",
      " 3   ICUSTAY_ID    float64\n",
      " 4   ITEMID        int64  \n",
      " 5   CHARTTIME     object \n",
      " 6   STORETIME     object \n",
      " 7   CGID          int64  \n",
      " 8   VALUE         object \n",
      " 9   VALUENUM      float64\n",
      " 10  VALUEUOM      object \n",
      " 11  WARNING       float64\n",
      " 12  ERROR         float64\n",
      " 13  RESULTSTATUS  object \n",
      " 14  STOPPED       object \n",
      "dtypes: float64(4), int64(5), object(6)\n",
      "memory usage: 1.1+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 140000000 to 149999999\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ROW_ID        int64  \n",
      " 1   SUBJECT_ID    int64  \n",
      " 2   HADM_ID       int64  \n",
      " 3   ICUSTAY_ID    float64\n",
      " 4   ITEMID        int64  \n",
      " 5   CHARTTIME     object \n",
      " 6   STORETIME     object \n",
      " 7   CGID          int64  \n",
      " 8   VALUE         object \n",
      " 9   VALUENUM      float64\n",
      " 10  VALUEUOM      object \n",
      " 11  WARNING       float64\n",
      " 12  ERROR         float64\n",
      " 13  RESULTSTATUS  object \n",
      " 14  STOPPED       object \n",
      "dtypes: float64(4), int64(5), object(6)\n",
      "memory usage: 1.1+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 150000000 to 159999999\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ROW_ID        int64  \n",
      " 1   SUBJECT_ID    int64  \n",
      " 2   HADM_ID       int64  \n",
      " 3   ICUSTAY_ID    float64\n",
      " 4   ITEMID        int64  \n",
      " 5   CHARTTIME     object \n",
      " 6   STORETIME     object \n",
      " 7   CGID          int64  \n",
      " 8   VALUE         object \n",
      " 9   VALUENUM      float64\n",
      " 10  VALUEUOM      object \n",
      " 11  WARNING       float64\n",
      " 12  ERROR         float64\n",
      " 13  RESULTSTATUS  object \n",
      " 14  STOPPED       object \n",
      "dtypes: float64(4), int64(5), object(6)\n",
      "memory usage: 1.1+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 160000000 to 169999999\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ROW_ID        int64  \n",
      " 1   SUBJECT_ID    int64  \n",
      " 2   HADM_ID       int64  \n",
      " 3   ICUSTAY_ID    float64\n",
      " 4   ITEMID        int64  \n",
      " 5   CHARTTIME     object \n",
      " 6   STORETIME     object \n",
      " 7   CGID          int64  \n",
      " 8   VALUE         object \n",
      " 9   VALUENUM      float64\n",
      " 10  VALUEUOM      object \n",
      " 11  WARNING       float64\n",
      " 12  ERROR         float64\n",
      " 13  RESULTSTATUS  object \n",
      " 14  STOPPED       object \n",
      "dtypes: float64(4), int64(5), object(6)\n",
      "memory usage: 1.1+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 170000000 to 179999999\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ROW_ID        int64  \n",
      " 1   SUBJECT_ID    int64  \n",
      " 2   HADM_ID       int64  \n",
      " 3   ICUSTAY_ID    float64\n",
      " 4   ITEMID        int64  \n",
      " 5   CHARTTIME     object \n",
      " 6   STORETIME     object \n",
      " 7   CGID          int64  \n",
      " 8   VALUE         object \n",
      " 9   VALUENUM      float64\n",
      " 10  VALUEUOM      object \n",
      " 11  WARNING       float64\n",
      " 12  ERROR         float64\n",
      " 13  RESULTSTATUS  object \n",
      " 14  STOPPED       object \n",
      "dtypes: float64(4), int64(5), object(6)\n",
      "memory usage: 1.1+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 180000000 to 189999999\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ROW_ID        int64  \n",
      " 1   SUBJECT_ID    int64  \n",
      " 2   HADM_ID       int64  \n",
      " 3   ICUSTAY_ID    float64\n",
      " 4   ITEMID        int64  \n",
      " 5   CHARTTIME     object \n",
      " 6   STORETIME     object \n",
      " 7   CGID          int64  \n",
      " 8   VALUE         object \n",
      " 9   VALUENUM      float64\n",
      " 10  VALUEUOM      object \n",
      " 11  WARNING       float64\n",
      " 12  ERROR         float64\n",
      " 13  RESULTSTATUS  object \n",
      " 14  STOPPED       object \n",
      "dtypes: float64(4), int64(5), object(6)\n",
      "memory usage: 1.1+ GB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parsa\\AppData\\Local\\Temp\\ipykernel_20108\\3443397845.py:10: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in chunk_iter:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 190000000 to 199999999\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ROW_ID        int64  \n",
      " 1   SUBJECT_ID    int64  \n",
      " 2   HADM_ID       int64  \n",
      " 3   ICUSTAY_ID    float64\n",
      " 4   ITEMID        int64  \n",
      " 5   CHARTTIME     object \n",
      " 6   STORETIME     object \n",
      " 7   CGID          int64  \n",
      " 8   VALUE         object \n",
      " 9   VALUENUM      float64\n",
      " 10  VALUEUOM      object \n",
      " 11  WARNING       float64\n",
      " 12  ERROR         float64\n",
      " 13  RESULTSTATUS  object \n",
      " 14  STOPPED       object \n",
      "dtypes: float64(4), int64(5), object(6)\n",
      "memory usage: 1.1+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 200000000 to 209999999\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ROW_ID        int64  \n",
      " 1   SUBJECT_ID    int64  \n",
      " 2   HADM_ID       int64  \n",
      " 3   ICUSTAY_ID    float64\n",
      " 4   ITEMID        int64  \n",
      " 5   CHARTTIME     object \n",
      " 6   STORETIME     object \n",
      " 7   CGID          int64  \n",
      " 8   VALUE         object \n",
      " 9   VALUENUM      float64\n",
      " 10  VALUEUOM      object \n",
      " 11  WARNING       float64\n",
      " 12  ERROR         float64\n",
      " 13  RESULTSTATUS  float64\n",
      " 14  STOPPED       object \n",
      "dtypes: float64(5), int64(5), object(5)\n",
      "memory usage: 1.1+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 210000000 to 219999999\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ROW_ID        int64  \n",
      " 1   SUBJECT_ID    int64  \n",
      " 2   HADM_ID       int64  \n",
      " 3   ICUSTAY_ID    float64\n",
      " 4   ITEMID        int64  \n",
      " 5   CHARTTIME     object \n",
      " 6   STORETIME     object \n",
      " 7   CGID          int64  \n",
      " 8   VALUE         object \n",
      " 9   VALUENUM      float64\n",
      " 10  VALUEUOM      object \n",
      " 11  WARNING       float64\n",
      " 12  ERROR         float64\n",
      " 13  RESULTSTATUS  float64\n",
      " 14  STOPPED       object \n",
      "dtypes: float64(5), int64(5), object(5)\n",
      "memory usage: 1.1+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 220000000 to 229999999\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ROW_ID        int64  \n",
      " 1   SUBJECT_ID    int64  \n",
      " 2   HADM_ID       int64  \n",
      " 3   ICUSTAY_ID    float64\n",
      " 4   ITEMID        int64  \n",
      " 5   CHARTTIME     object \n",
      " 6   STORETIME     object \n",
      " 7   CGID          int64  \n",
      " 8   VALUE         object \n",
      " 9   VALUENUM      float64\n",
      " 10  VALUEUOM      object \n",
      " 11  WARNING       float64\n",
      " 12  ERROR         float64\n",
      " 13  RESULTSTATUS  float64\n",
      " 14  STOPPED       object \n",
      "dtypes: float64(5), int64(5), object(5)\n",
      "memory usage: 1.1+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 230000000 to 239999999\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ROW_ID        int64  \n",
      " 1   SUBJECT_ID    int64  \n",
      " 2   HADM_ID       int64  \n",
      " 3   ICUSTAY_ID    float64\n",
      " 4   ITEMID        int64  \n",
      " 5   CHARTTIME     object \n",
      " 6   STORETIME     object \n",
      " 7   CGID          int64  \n",
      " 8   VALUE         object \n",
      " 9   VALUENUM      float64\n",
      " 10  VALUEUOM      object \n",
      " 11  WARNING       float64\n",
      " 12  ERROR         float64\n",
      " 13  RESULTSTATUS  float64\n",
      " 14  STOPPED       object \n",
      "dtypes: float64(5), int64(5), object(5)\n",
      "memory usage: 1.1+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 240000000 to 249999999\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ROW_ID        int64  \n",
      " 1   SUBJECT_ID    int64  \n",
      " 2   HADM_ID       int64  \n",
      " 3   ICUSTAY_ID    float64\n",
      " 4   ITEMID        int64  \n",
      " 5   CHARTTIME     object \n",
      " 6   STORETIME     object \n",
      " 7   CGID          int64  \n",
      " 8   VALUE         object \n",
      " 9   VALUENUM      float64\n",
      " 10  VALUEUOM      object \n",
      " 11  WARNING       float64\n",
      " 12  ERROR         float64\n",
      " 13  RESULTSTATUS  float64\n",
      " 14  STOPPED       object \n",
      "dtypes: float64(5), int64(5), object(5)\n",
      "memory usage: 1.1+ GB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parsa\\AppData\\Local\\Temp\\ipykernel_20108\\3443397845.py:10: DtypeWarning: Columns (8,10,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in chunk_iter:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 250000000 to 259999999\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ROW_ID        int64  \n",
      " 1   SUBJECT_ID    int64  \n",
      " 2   HADM_ID       int64  \n",
      " 3   ICUSTAY_ID    float64\n",
      " 4   ITEMID        int64  \n",
      " 5   CHARTTIME     object \n",
      " 6   STORETIME     object \n",
      " 7   CGID          int64  \n",
      " 8   VALUE         object \n",
      " 9   VALUENUM      float64\n",
      " 10  VALUEUOM      object \n",
      " 11  WARNING       float64\n",
      " 12  ERROR         float64\n",
      " 13  RESULTSTATUS  float64\n",
      " 14  STOPPED       object \n",
      "dtypes: float64(5), int64(5), object(5)\n",
      "memory usage: 1.1+ GB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parsa\\AppData\\Local\\Temp\\ipykernel_20108\\3443397845.py:10: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in chunk_iter:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 260000000 to 269999999\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ROW_ID        int64  \n",
      " 1   SUBJECT_ID    int64  \n",
      " 2   HADM_ID       int64  \n",
      " 3   ICUSTAY_ID    float64\n",
      " 4   ITEMID        int64  \n",
      " 5   CHARTTIME     object \n",
      " 6   STORETIME     object \n",
      " 7   CGID          int64  \n",
      " 8   VALUE         object \n",
      " 9   VALUENUM      float64\n",
      " 10  VALUEUOM      float64\n",
      " 11  WARNING       int64  \n",
      " 12  ERROR         int64  \n",
      " 13  RESULTSTATUS  float64\n",
      " 14  STOPPED       float64\n",
      "dtypes: float64(5), int64(7), object(3)\n",
      "memory usage: 1.1+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 270000000 to 279999999\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ROW_ID        int64  \n",
      " 1   SUBJECT_ID    int64  \n",
      " 2   HADM_ID       int64  \n",
      " 3   ICUSTAY_ID    float64\n",
      " 4   ITEMID        int64  \n",
      " 5   CHARTTIME     object \n",
      " 6   STORETIME     object \n",
      " 7   CGID          int64  \n",
      " 8   VALUE         object \n",
      " 9   VALUENUM      float64\n",
      " 10  VALUEUOM      float64\n",
      " 11  WARNING       int64  \n",
      " 12  ERROR         int64  \n",
      " 13  RESULTSTATUS  float64\n",
      " 14  STOPPED       float64\n",
      "dtypes: float64(5), int64(7), object(3)\n",
      "memory usage: 1.1+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 280000000 to 289999999\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ROW_ID        int64  \n",
      " 1   SUBJECT_ID    int64  \n",
      " 2   HADM_ID       int64  \n",
      " 3   ICUSTAY_ID    float64\n",
      " 4   ITEMID        int64  \n",
      " 5   CHARTTIME     object \n",
      " 6   STORETIME     object \n",
      " 7   CGID          int64  \n",
      " 8   VALUE         object \n",
      " 9   VALUENUM      float64\n",
      " 10  VALUEUOM      float64\n",
      " 11  WARNING       int64  \n",
      " 12  ERROR         int64  \n",
      " 13  RESULTSTATUS  float64\n",
      " 14  STOPPED       float64\n",
      "dtypes: float64(5), int64(7), object(3)\n",
      "memory usage: 1.1+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 290000000 to 299999999\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   ROW_ID        int64  \n",
      " 1   SUBJECT_ID    int64  \n",
      " 2   HADM_ID       int64  \n",
      " 3   ICUSTAY_ID    float64\n",
      " 4   ITEMID        int64  \n",
      " 5   CHARTTIME     object \n",
      " 6   STORETIME     object \n",
      " 7   CGID          int64  \n",
      " 8   VALUE         object \n",
      " 9   VALUENUM      float64\n",
      " 10  VALUEUOM      float64\n",
      " 11  WARNING       int64  \n",
      " 12  ERROR         int64  \n",
      " 13  RESULTSTATUS  float64\n",
      " 14  STOPPED       float64\n",
      "dtypes: float64(5), int64(7), object(3)\n",
      "memory usage: 1.1+ GB\n",
      "None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 10\u001B[0m\n\u001B[0;32m      7\u001B[0m chunk_iter \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCHARTEVENTS.csv\u001B[39m\u001B[38;5;124m'\u001B[39m, chunksize\u001B[38;5;241m=\u001B[39mchunk_size)\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# Process each chunk\u001B[39;00m\n\u001B[1;32m---> 10\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m chunk_iter:\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;28mprint\u001B[39m(chunk\u001B[38;5;241m.\u001B[39minfo())\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1843\u001B[0m, in \u001B[0;36mTextFileReader.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1841\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame:\n\u001B[0;32m   1842\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1843\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_chunk()\n\u001B[0;32m   1844\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[0;32m   1845\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1985\u001B[0m, in \u001B[0;36mTextFileReader.get_chunk\u001B[1;34m(self, size)\u001B[0m\n\u001B[0;32m   1983\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n\u001B[0;32m   1984\u001B[0m     size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmin\u001B[39m(size, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnrows \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_currow)\n\u001B[1;32m-> 1985\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread(nrows\u001B[38;5;241m=\u001B[39msize)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001B[0m, in \u001B[0;36mTextFileReader.read\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m   1916\u001B[0m nrows \u001B[38;5;241m=\u001B[39m validate_integer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnrows\u001B[39m\u001B[38;5;124m\"\u001B[39m, nrows)\n\u001B[0;32m   1917\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1918\u001B[0m     \u001B[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001B[39;00m\n\u001B[0;32m   1919\u001B[0m     (\n\u001B[0;32m   1920\u001B[0m         index,\n\u001B[0;32m   1921\u001B[0m         columns,\n\u001B[0;32m   1922\u001B[0m         col_dict,\n\u001B[1;32m-> 1923\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mread(  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[0;32m   1924\u001B[0m         nrows\n\u001B[0;32m   1925\u001B[0m     )\n\u001B[0;32m   1926\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m   1927\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001B[0m, in \u001B[0;36mCParserWrapper.read\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m    232\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    233\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlow_memory:\n\u001B[1;32m--> 234\u001B[0m         chunks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reader\u001B[38;5;241m.\u001B[39mread_low_memory(nrows)\n\u001B[0;32m    235\u001B[0m         \u001B[38;5;66;03m# destructive to chunks\u001B[39;00m\n\u001B[0;32m    236\u001B[0m         data \u001B[38;5;241m=\u001B[39m _concatenate_chunks(chunks)\n",
      "File \u001B[1;32mparsers.pyx:850\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mparsers.pyx:905\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._read_rows\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mparsers.pyx:874\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mparsers.pyx:891\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mparsers.pyx:2053\u001B[0m, in \u001B[0;36mpandas._libs.parsers.raise_parser_error\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\codecs.py:331\u001B[0m, in \u001B[0;36mBufferedIncrementalDecoder.getstate\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    328\u001B[0m     IncrementalDecoder\u001B[38;5;241m.\u001B[39mreset(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m    329\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuffer \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 331\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgetstate\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    332\u001B[0m     \u001B[38;5;66;03m# additional state info is always 0\u001B[39;00m\n\u001B[0;32m    333\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuffer, \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m    335\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msetstate\u001B[39m(\u001B[38;5;28mself\u001B[39m, state):\n\u001B[0;32m    336\u001B[0m     \u001B[38;5;66;03m# ignore additional state info\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T10:31:29.986349Z",
     "start_time": "2024-12-06T10:27:17.935405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import polars as pl\n",
    "\n",
    "# Load the CSV file\n",
    "df = pl.read_csv('CHARTEVENTS.csv')\n",
    "\n",
    "# Perform operations\n",
    "df.head()\n"
   ],
   "id": "959a7a39d7655935",
   "outputs": [
    {
     "ename": "ComputeError",
     "evalue": "could not parse `\"No\"` as dtype `f64` at column 'VALUE' (column number 9)\n\nThe current offset in the file is 14942304 bytes.\n\nYou might want to try:\n- increasing `infer_schema_length` (e.g. `infer_schema_length=10000`),\n- specifying correct dtype with the `schema_overrides` argument\n- setting `ignore_errors` to `True`,\n- adding `\"No\"` to the `null_values` list.\n\nOriginal error: ```remaining bytes non-empty```",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mComputeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpolars\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpl\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Load the CSV file\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m df \u001B[38;5;241m=\u001B[39m pl\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCHARTEVENTS.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# Perform operations\u001B[39;00m\n\u001B[0;32m      7\u001B[0m df\u001B[38;5;241m.\u001B[39mhead()\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\polars\\_utils\\deprecation.py:92\u001B[0m, in \u001B[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     87\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(function)\n\u001B[0;32m     88\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs: P\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: P\u001B[38;5;241m.\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m T:\n\u001B[0;32m     89\u001B[0m     _rename_keyword_argument(\n\u001B[0;32m     90\u001B[0m         old_name, new_name, kwargs, function\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m, version\n\u001B[0;32m     91\u001B[0m     )\n\u001B[1;32m---> 92\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m function(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\polars\\_utils\\deprecation.py:92\u001B[0m, in \u001B[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     87\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(function)\n\u001B[0;32m     88\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs: P\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: P\u001B[38;5;241m.\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m T:\n\u001B[0;32m     89\u001B[0m     _rename_keyword_argument(\n\u001B[0;32m     90\u001B[0m         old_name, new_name, kwargs, function\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m, version\n\u001B[0;32m     91\u001B[0m     )\n\u001B[1;32m---> 92\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m function(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\polars\\_utils\\deprecation.py:92\u001B[0m, in \u001B[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     87\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(function)\n\u001B[0;32m     88\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs: P\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: P\u001B[38;5;241m.\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m T:\n\u001B[0;32m     89\u001B[0m     _rename_keyword_argument(\n\u001B[0;32m     90\u001B[0m         old_name, new_name, kwargs, function\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m, version\n\u001B[0;32m     91\u001B[0m     )\n\u001B[1;32m---> 92\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m function(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\polars\\io\\csv\\functions.py:527\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(source, has_header, columns, new_columns, separator, comment_prefix, quote_char, skip_rows, schema, schema_overrides, null_values, missing_utf8_is_empty_string, ignore_errors, try_parse_dates, n_threads, infer_schema, infer_schema_length, batch_size, n_rows, encoding, low_memory, rechunk, use_pyarrow, storage_options, skip_rows_after_header, row_index_name, row_index_offset, sample_size, eol_char, raise_if_empty, truncate_ragged_lines, decimal_comma, glob)\u001B[0m\n\u001B[0;32m    519\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    520\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m prepare_file_arg(\n\u001B[0;32m    521\u001B[0m         source,\n\u001B[0;32m    522\u001B[0m         encoding\u001B[38;5;241m=\u001B[39mencoding,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    525\u001B[0m         storage_options\u001B[38;5;241m=\u001B[39mstorage_options,\n\u001B[0;32m    526\u001B[0m     ) \u001B[38;5;28;01mas\u001B[39;00m data:\n\u001B[1;32m--> 527\u001B[0m         df \u001B[38;5;241m=\u001B[39m _read_csv_impl(\n\u001B[0;32m    528\u001B[0m             data,\n\u001B[0;32m    529\u001B[0m             has_header\u001B[38;5;241m=\u001B[39mhas_header,\n\u001B[0;32m    530\u001B[0m             columns\u001B[38;5;241m=\u001B[39mcolumns \u001B[38;5;28;01mif\u001B[39;00m columns \u001B[38;5;28;01melse\u001B[39;00m projection,\n\u001B[0;32m    531\u001B[0m             separator\u001B[38;5;241m=\u001B[39mseparator,\n\u001B[0;32m    532\u001B[0m             comment_prefix\u001B[38;5;241m=\u001B[39mcomment_prefix,\n\u001B[0;32m    533\u001B[0m             quote_char\u001B[38;5;241m=\u001B[39mquote_char,\n\u001B[0;32m    534\u001B[0m             skip_rows\u001B[38;5;241m=\u001B[39mskip_rows,\n\u001B[0;32m    535\u001B[0m             schema_overrides\u001B[38;5;241m=\u001B[39mschema_overrides,\n\u001B[0;32m    536\u001B[0m             schema\u001B[38;5;241m=\u001B[39mschema,\n\u001B[0;32m    537\u001B[0m             null_values\u001B[38;5;241m=\u001B[39mnull_values,\n\u001B[0;32m    538\u001B[0m             missing_utf8_is_empty_string\u001B[38;5;241m=\u001B[39mmissing_utf8_is_empty_string,\n\u001B[0;32m    539\u001B[0m             ignore_errors\u001B[38;5;241m=\u001B[39mignore_errors,\n\u001B[0;32m    540\u001B[0m             try_parse_dates\u001B[38;5;241m=\u001B[39mtry_parse_dates,\n\u001B[0;32m    541\u001B[0m             n_threads\u001B[38;5;241m=\u001B[39mn_threads,\n\u001B[0;32m    542\u001B[0m             infer_schema_length\u001B[38;5;241m=\u001B[39minfer_schema_length,\n\u001B[0;32m    543\u001B[0m             batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m    544\u001B[0m             n_rows\u001B[38;5;241m=\u001B[39mn_rows,\n\u001B[0;32m    545\u001B[0m             encoding\u001B[38;5;241m=\u001B[39mencoding \u001B[38;5;28;01mif\u001B[39;00m encoding \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf8-lossy\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf8\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    546\u001B[0m             low_memory\u001B[38;5;241m=\u001B[39mlow_memory,\n\u001B[0;32m    547\u001B[0m             rechunk\u001B[38;5;241m=\u001B[39mrechunk,\n\u001B[0;32m    548\u001B[0m             skip_rows_after_header\u001B[38;5;241m=\u001B[39mskip_rows_after_header,\n\u001B[0;32m    549\u001B[0m             row_index_name\u001B[38;5;241m=\u001B[39mrow_index_name,\n\u001B[0;32m    550\u001B[0m             row_index_offset\u001B[38;5;241m=\u001B[39mrow_index_offset,\n\u001B[0;32m    551\u001B[0m             eol_char\u001B[38;5;241m=\u001B[39meol_char,\n\u001B[0;32m    552\u001B[0m             raise_if_empty\u001B[38;5;241m=\u001B[39mraise_if_empty,\n\u001B[0;32m    553\u001B[0m             truncate_ragged_lines\u001B[38;5;241m=\u001B[39mtruncate_ragged_lines,\n\u001B[0;32m    554\u001B[0m             decimal_comma\u001B[38;5;241m=\u001B[39mdecimal_comma,\n\u001B[0;32m    555\u001B[0m             glob\u001B[38;5;241m=\u001B[39mglob,\n\u001B[0;32m    556\u001B[0m         )\n\u001B[0;32m    558\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m new_columns:\n\u001B[0;32m    559\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _update_columns(df, new_columns)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\polars\\io\\csv\\functions.py:672\u001B[0m, in \u001B[0;36m_read_csv_impl\u001B[1;34m(source, has_header, columns, separator, comment_prefix, quote_char, skip_rows, schema, schema_overrides, null_values, missing_utf8_is_empty_string, ignore_errors, try_parse_dates, n_threads, infer_schema_length, batch_size, n_rows, encoding, low_memory, rechunk, skip_rows_after_header, row_index_name, row_index_offset, sample_size, eol_char, raise_if_empty, truncate_ragged_lines, decimal_comma, glob)\u001B[0m\n\u001B[0;32m    668\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[0;32m    670\u001B[0m projection, columns \u001B[38;5;241m=\u001B[39m parse_columns_arg(columns)\n\u001B[1;32m--> 672\u001B[0m pydf \u001B[38;5;241m=\u001B[39m PyDataFrame\u001B[38;5;241m.\u001B[39mread_csv(\n\u001B[0;32m    673\u001B[0m     source,\n\u001B[0;32m    674\u001B[0m     infer_schema_length,\n\u001B[0;32m    675\u001B[0m     batch_size,\n\u001B[0;32m    676\u001B[0m     has_header,\n\u001B[0;32m    677\u001B[0m     ignore_errors,\n\u001B[0;32m    678\u001B[0m     n_rows,\n\u001B[0;32m    679\u001B[0m     skip_rows,\n\u001B[0;32m    680\u001B[0m     projection,\n\u001B[0;32m    681\u001B[0m     separator,\n\u001B[0;32m    682\u001B[0m     rechunk,\n\u001B[0;32m    683\u001B[0m     columns,\n\u001B[0;32m    684\u001B[0m     encoding,\n\u001B[0;32m    685\u001B[0m     n_threads,\n\u001B[0;32m    686\u001B[0m     path,\n\u001B[0;32m    687\u001B[0m     dtype_list,\n\u001B[0;32m    688\u001B[0m     dtype_slice,\n\u001B[0;32m    689\u001B[0m     low_memory,\n\u001B[0;32m    690\u001B[0m     comment_prefix,\n\u001B[0;32m    691\u001B[0m     quote_char,\n\u001B[0;32m    692\u001B[0m     processed_null_values,\n\u001B[0;32m    693\u001B[0m     missing_utf8_is_empty_string,\n\u001B[0;32m    694\u001B[0m     try_parse_dates,\n\u001B[0;32m    695\u001B[0m     skip_rows_after_header,\n\u001B[0;32m    696\u001B[0m     parse_row_index_args(row_index_name, row_index_offset),\n\u001B[0;32m    697\u001B[0m     eol_char\u001B[38;5;241m=\u001B[39meol_char,\n\u001B[0;32m    698\u001B[0m     raise_if_empty\u001B[38;5;241m=\u001B[39mraise_if_empty,\n\u001B[0;32m    699\u001B[0m     truncate_ragged_lines\u001B[38;5;241m=\u001B[39mtruncate_ragged_lines,\n\u001B[0;32m    700\u001B[0m     decimal_comma\u001B[38;5;241m=\u001B[39mdecimal_comma,\n\u001B[0;32m    701\u001B[0m     schema\u001B[38;5;241m=\u001B[39mschema,\n\u001B[0;32m    702\u001B[0m )\n\u001B[0;32m    703\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m wrap_df(pydf)\n",
      "\u001B[1;31mComputeError\u001B[0m: could not parse `\"No\"` as dtype `f64` at column 'VALUE' (column number 9)\n\nThe current offset in the file is 14942304 bytes.\n\nYou might want to try:\n- increasing `infer_schema_length` (e.g. `infer_schema_length=10000`),\n- specifying correct dtype with the `schema_overrides` argument\n- setting `ignore_errors` to `True`,\n- adding `\"No\"` to the `null_values` list.\n\nOriginal error: ```remaining bytes non-empty```"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:28:25.501261Z",
     "start_time": "2024-12-06T11:28:22.367475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "# Load the dataset with Dask\n",
    "df = dd.read_csv('CHARTEVENTS.csv')\n",
    "\n",
    "# Perform operations\n",
    "df.head()  # Display the first few rows"
   ],
   "id": "49e86229a7e7e239",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mismatched dtypes found in `pd.read_csv`/`pd.read_table`.\n\n+------------+---------+----------+\n| Column     | Found   | Expected |\n+------------+---------+----------+\n| CGID       | float64 | int64    |\n| ICUSTAY_ID | float64 | int64    |\n+------------+---------+----------+\n\nUsually this is due to dask's dtype inference failing, and\n*may* be fixed by specifying dtypes manually by adding:\n\ndtype={'CGID': 'float64',\n       'ICUSTAY_ID': 'float64'}\n\nto the call to `read_csv`/`read_table`.\n\nAlternatively, provide `assume_missing=True` to interpret\nall unspecified integer columns as floats.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m df \u001B[38;5;241m=\u001B[39m dd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCHARTEVENTS.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# Perform operations\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m df\u001B[38;5;241m.\u001B[39mhead()\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\dask\\dataframe\\core.py:1563\u001B[0m, in \u001B[0;36m_Frame.head\u001B[1;34m(self, n, npartitions, compute)\u001B[0m\n\u001B[0;32m   1561\u001B[0m \u001B[38;5;66;03m# No need to warn if we're already looking at all partitions\u001B[39;00m\n\u001B[0;32m   1562\u001B[0m safe \u001B[38;5;241m=\u001B[39m npartitions \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnpartitions\n\u001B[1;32m-> 1563\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_head(n\u001B[38;5;241m=\u001B[39mn, npartitions\u001B[38;5;241m=\u001B[39mnpartitions, compute\u001B[38;5;241m=\u001B[39mcompute, safe\u001B[38;5;241m=\u001B[39msafe)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\dask\\dataframe\\core.py:1597\u001B[0m, in \u001B[0;36m_Frame._head\u001B[1;34m(self, n, npartitions, compute, safe)\u001B[0m\n\u001B[0;32m   1592\u001B[0m result \u001B[38;5;241m=\u001B[39m new_dd_object(\n\u001B[0;32m   1593\u001B[0m     graph, name, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_meta, [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdivisions[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdivisions[npartitions]]\n\u001B[0;32m   1594\u001B[0m )\n\u001B[0;32m   1596\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m compute:\n\u001B[1;32m-> 1597\u001B[0m     result \u001B[38;5;241m=\u001B[39m result\u001B[38;5;241m.\u001B[39mcompute()\n\u001B[0;32m   1598\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\dask\\base.py:372\u001B[0m, in \u001B[0;36mDaskMethodsMixin.compute\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m    348\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    349\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Compute this dask collection\u001B[39;00m\n\u001B[0;32m    350\u001B[0m \n\u001B[0;32m    351\u001B[0m \u001B[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    370\u001B[0m \u001B[38;5;124;03m    dask.compute\u001B[39;00m\n\u001B[0;32m    371\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 372\u001B[0m     (result,) \u001B[38;5;241m=\u001B[39m compute(\u001B[38;5;28mself\u001B[39m, traverse\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    373\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\dask\\base.py:660\u001B[0m, in \u001B[0;36mcompute\u001B[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001B[0m\n\u001B[0;32m    657\u001B[0m     postcomputes\u001B[38;5;241m.\u001B[39mappend(x\u001B[38;5;241m.\u001B[39m__dask_postcompute__())\n\u001B[0;32m    659\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m shorten_traceback():\n\u001B[1;32m--> 660\u001B[0m     results \u001B[38;5;241m=\u001B[39m schedule(dsk, keys, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    662\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m repack([f(r, \u001B[38;5;241m*\u001B[39ma) \u001B[38;5;28;01mfor\u001B[39;00m r, (f, a) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(results, postcomputes)])\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:144\u001B[0m, in \u001B[0;36mCSVFunctionWrapper.__call__\u001B[1;34m(self, part)\u001B[0m\n\u001B[0;32m    141\u001B[0m         rest_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124musecols\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m columns\n\u001B[0;32m    143\u001B[0m \u001B[38;5;66;03m# Call `pandas_read_text`\u001B[39;00m\n\u001B[1;32m--> 144\u001B[0m df \u001B[38;5;241m=\u001B[39m pandas_read_text(\n\u001B[0;32m    145\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreader,\n\u001B[0;32m    146\u001B[0m     block,\n\u001B[0;32m    147\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mheader,\n\u001B[0;32m    148\u001B[0m     rest_kwargs,\n\u001B[0;32m    149\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtypes,\n\u001B[0;32m    150\u001B[0m     columns,\n\u001B[0;32m    151\u001B[0m     write_header,\n\u001B[0;32m    152\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menforce,\n\u001B[0;32m    153\u001B[0m     path_info,\n\u001B[0;32m    154\u001B[0m )\n\u001B[0;32m    155\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m project_after_read:\n\u001B[0;32m    156\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m df[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns]\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:199\u001B[0m, in \u001B[0;36mpandas_read_text\u001B[1;34m(reader, b, header, kwargs, dtypes, columns, write_header, enforce, path)\u001B[0m\n\u001B[0;32m    197\u001B[0m df \u001B[38;5;241m=\u001B[39m reader(bio, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    198\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtypes:\n\u001B[1;32m--> 199\u001B[0m     coerce_dtypes(df, dtypes)\n\u001B[0;32m    201\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m enforce \u001B[38;5;129;01mand\u001B[39;00m columns \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mlist\u001B[39m(df\u001B[38;5;241m.\u001B[39mcolumns) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlist\u001B[39m(columns)):\n\u001B[0;32m    202\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mColumns do not match\u001B[39m\u001B[38;5;124m\"\u001B[39m, df\u001B[38;5;241m.\u001B[39mcolumns, columns)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:300\u001B[0m, in \u001B[0;36mcoerce_dtypes\u001B[1;34m(df, dtypes)\u001B[0m\n\u001B[0;32m    296\u001B[0m rule \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m61\u001B[39m)\n\u001B[0;32m    297\u001B[0m msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMismatched dtypes found in `pd.read_csv`/`pd.read_table`.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (\n\u001B[0;32m    298\u001B[0m     rule\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mfilter\u001B[39m(\u001B[38;5;28;01mNone\u001B[39;00m, [dtype_msg, date_msg]))\n\u001B[0;32m    299\u001B[0m )\n\u001B[1;32m--> 300\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n",
      "\u001B[1;31mValueError\u001B[0m: Mismatched dtypes found in `pd.read_csv`/`pd.read_table`.\n\n+------------+---------+----------+\n| Column     | Found   | Expected |\n+------------+---------+----------+\n| CGID       | float64 | int64    |\n| ICUSTAY_ID | float64 | int64    |\n+------------+---------+----------+\n\nUsually this is due to dask's dtype inference failing, and\n*may* be fixed by specifying dtypes manually by adding:\n\ndtype={'CGID': 'float64',\n       'ICUSTAY_ID': 'float64'}\n\nto the call to `read_csv`/`read_table`.\n\nAlternatively, provide `assume_missing=True` to interpret\nall unspecified integer columns as floats."
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
